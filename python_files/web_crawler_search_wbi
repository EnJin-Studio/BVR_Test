import time
import csv
import requests
import random
import os
import pandas as pd
from datetime import datetime
from html import unescape
import re
import hashlib
import urllib.parse

partition_tid = 4  #游戏分区

# Headers
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36",
    "Referer": "https://search.bilibili.com",
    "Origin": "https://search.bilibili.com",
    "Accept": "application/json",
    "Accept-Language": "zh-CN,zh;q=0.9",
    "Cookie": "_uuid=810D1082B9-F1073-81106-59101-E759C98F3F6F91420infoc; buvid_fp=4efefeec27f4b6797c2d67e3f6431784; buvid3=5DCD4719-61DA-AB7F-DAB1-8E4264DDC26A05662infoc; b_nut=1749940793; buvid4=445080EE-6521-E55B-622B-BD87E123894305662-025061506-Csu38aAzj1bTMozpd574CA%3D%3D; enable_web_push=DISABLE; enable_feed_channel=ENABLE; rpdid=|(ukR|ukYl))0J'u~RmmR)J|l; home_feed_column=5; browser_resolution=1707-872; header_theme_version=OPEN; theme-tip-show=SHOWED; theme-avatar-tip-show=SHOWED; bili_ticket=eyJhbGciOiJIUzI1NiIsImtpZCI6InMwMyIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3NTE0NzA3MDcsImlhdCI6MTc1MTIxMTQ0NywicGx0IjotMX0.K_jvbrspu3HQ0OVeGFEcFMQoOyqxi9ZocQvVSIf2JxM; bili_ticket_expires=1751470647; theme-switch-show=SHOWED; CURRENT_FNVAL=2000; b_lsid=85D1810E4_197C20C86A4; SESSDATA=d51b8604%2C1766861007%2C860e0%2A72CjDvU1TwGKHsFt5SeuRpvX5kBJ0hHh23ek7QLtkdJqsImfQd6mHcImAvUUTuZaMwi-YSVkdfXy12bzFhYWxMMzU0UG9hOUZzNzNjRlRIVnlmbHRYbWxmSDlhM1MwRVQwaklBbnJDVm9tNmVjNm5sUGh0c0d2VW4tN09VbmFTUGk0SmRnbFlRN2x3IIEC; bili_jct=f207dcaff31357caf5bb30f1a0b7acde; DedeUserID=3546928264514104; DedeUserID__ckMd5=52650340348bfac8; sid=qjc33qr5;"
}

def clean_html(text):
    text = unescape(text)
    return re.sub(r'<[^>]+>', '', text)

def parse_duration_to_seconds(duration_str):
    parts = duration_str.split(":")
    try:
        if len(parts) == 3:
            h, m, s = map(int, parts)
            return h * 3600 + m * 60 + s
        elif len(parts) == 2:
            m, s = map(int, parts)
            return m * 60 + s
    except:
        pass
    return 0

def parse_search_items(data, start_ts, end_ts):
    items = []
    for v in data.get('data', {}).get('result', []):
        pub = v.get('pubdate', 0)
        if pub < start_ts or pub >= end_ts: continue
        items.append({
            "bvid": v.get("bvid"),
            "title": clean_html(v.get("title","")),
            "pic": v.get("pic"),
            "duration": parse_duration_to_seconds(v.get("duration","0:00")),
            "pub_seconds_ago": int(time.time() - pub),
            "view_count": v.get("play"),
            "danmaku_count": int(v.get("video_review","0")),
            "uploader_name": v.get("author"),
            "uploader_mid": v.get("mid")
        })
    return items

def get_follower_count(mid):
    try:
        resp = requests.get("https://api.bilibili.com/x/relation/stat",
                             params={"vmid": mid}, headers=HEADERS, timeout=5)
        return resp.json().get("data",{}).get("follower")
    except:
        return None

def fetch_wbi_keys():
    url = "https://api.bilibili.com/x/web-interface/nav"
    try:
        resp = requests.get(url, headers=HEADERS, timeout=5)
        resp.raise_for_status()
        data = resp.json().get("data", {}).get("wbi_img", {})
        img_url = data.get("img_url", "")
        sub_url = data.get("sub_url", "")

        img_key = img_url.split("/")[-1].split(".")[0]
        sub_key = sub_url.split("/")[-1].split(".")[0]

        print(f"[DEBUG] img_key: {img_key} ({len(img_key)})")
        print(f"[DEBUG] sub_key: {sub_key} ({len(sub_key)})")

        if len(img_key) != 32 or len(sub_key) != 32:
            raise ValueError("img_key 或 sub_key 长度不是 32，请检查 API 返回格式")

        return img_key, sub_key

    except Exception as e:
        print(f"[ERROR] 获取 WBI 签名 key 失败: {e}")
        return None, None

# 伪装wbi签名
def encode_wbi(params, img_key, sub_key):
    mixin_source = img_key + sub_key

    table = [46, 47, 18, 2, 8, 36, 12, 23, 25, 13,
             0, 29, 48, 39, 4, 32, 50, 19, 31, 43,
             26, 10, 9, 38, 27, 15, 3, 28, 14, 5,
             35, 11, 37, 1, 34, 41, 16, 49, 7, 42,
             22, 17, 30, 24, 21, 6, 33, 40, 20, 44]

    mixin_key = ''.join([mixin_source[i] for i in table])
    params['wts'] = str(int(time.time()))
    sorted_query = '&'.join(f"{k}={urllib.parse.quote_plus(str(params[k]))}" for k in sorted(params))
    params['w_rid'] = hashlib.md5((sorted_query + mixin_key).encode()).hexdigest()

    return params

    
def main(keywords, start_date, end_date, pages=50, delay=2):
    os.makedirs("csv_data", exist_ok=True)
    history = "csv_data/video_wbi.csv"

    seen = set()
    if os.path.exists(history):
        seen = set(pd.read_csv(history)["bvid"].dropna().tolist())

    start_ts = int(datetime.strptime(start_date,"%Y-%m-%d").timestamp())
    end_ts = int(datetime.strptime(end_date,"%Y-%m-%d").timestamp())

    img_key, sub_key = fetch_wbi_keys()
    if not img_key or not sub_key:
        print("[ERROR] 无法获取 WBI 签名 key，终止爬取")
        return

    all_items=[]
    for kw in keywords:
        print(f"[KEYWORD] {kw}")
        for page in range(1, pages+1):
            params={"search_type":"video","keyword":kw,"page":page,"tids": partition_tid}
            full = encode_wbi(params, img_key, sub_key)
            resp = requests.get("https://api.bilibili.com/x/web-interface/wbi/search/type",
                                params=full, headers=HEADERS, timeout=10)
            if resp.status_code!=200:
                print(f"[WARN] 第{page}页状态 {resp.status_code}")
                break
            data = resp.json()
            items=parse_search_items(data, start_ts, end_ts)
            for it in items:
                bvid=it["bvid"]
                if bvid and bvid not in seen:
                    it["uploader_follower"]=get_follower_count(it["uploader_mid"])
                    it.pop("uploader_mid",None)
                    all_items.append(it)
                    seen.add(bvid)
            print(f" → 第{page}页新增{len(items)}条")
            time.sleep(delay + random.random())

    df=pd.DataFrame(all_items)
    ts=datetime.now().strftime("%Y%m%d_%H%M%S")
    batch=f"csv_data/wbi_{ts}.csv"
    df.to_csv(batch,index=False,encoding='utf-8-sig')
    print(f"[SAVE] 批次保存: {batch}")

    if os.path.exists(history):
        df_hist=pd.read_csv(history)
        df_all=pd.concat([df,df_hist]).drop_duplicates("bvid")
    else:
        df_all=df
    df_all.to_csv(history,index=False,encoding='utf-8-sig')
    print(f"[DONE] 合并完毕,共 {len(df_all)} 条")

if __name__ == "__main__":
    kw=["游戏"]
    main(kw, "2024-01-01", "2025-06-30", pages=60, delay=2)
